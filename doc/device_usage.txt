http://ffmpeg.gusari.org/viewtopic.php?f=8&t=1274



#include <libavcodec/avcodec.h>
#include <libavformat/avformat.h>
#include <libswscale/swscale.h>
#include <libavdevice/avdevice.h>

#include <assert.h>
#include <stdio.h>

void SaveFrame(AVFrame *pFrame, int width, int height, int iFrame)
{
               FILE *pFile;
    char szFilename[32];
    int y;

    // Open file
    sprintf(szFilename, "frame%d.ppm", iFrame);
    pFile = fopen(szFilename, "wb");
    if (pFile == NULL)
        return;

    // Write header
    fprintf(pFile, "P6\n%d %d\n255\n", width, height);

    // Write pixel data
    for (y = 0; y < height; y++)
        fwrite(pFrame->data[0] + y * pFrame->linesize[0],
        1, width * 3, pFile);

    // Close file
    fclose(pFile);
}

int main(int argc, char *argv[])
{

    AVFormatContext *pFormatCtx = NULL;
    int i, videoStream;
    AVCodecContext *pCodecCtx;
    AVCodec *pCodec;
    AVFrame *pFrame;
    AVFrame *pFrameCropped;
    AVFrame *pFrameRGB;
    struct SwsContext * pSwsCtx;
    AVPacket packet;
    int frameFinished;
    int numBytes;
    int numBytesCroped;
    uint8_t *buffer;
    uint8_t *bufferCroped;

    AVDictionary * p_options = NULL;
    AVInputFormat * p_in_fmt = NULL;

    // Register all formats and codecs
    av_register_all();
    avcodec_register_all();
    avdevice_register_all();

    av_dict_set(&p_options, "framerate", "25", 0);
    av_dict_set(&p_options, "video_size", "800x600", 0);
    p_in_fmt = av_find_input_format("x11grab");

    // Open video file
    if (avformat_open_input(&pFormatCtx, ":0.0",
                            p_in_fmt, &p_options) != 0)
    {
        printf("cannot open input file!\n");
        return -1; // Couldn't open file
    }

    // Retrieve stream information
    if (avformat_find_stream_info(pFormatCtx, NULL) < 0)
        return -1; // Couldn't find stream information

    // Dump information about file onto standard error
    av_dump_format(pFormatCtx, 0, argv[1], 0);

    // Find the first video stream
    videoStream = -1;
    for (i = 0; i < pFormatCtx->nb_streams; i++)
    if (pFormatCtx->streams[i]->codec->codec_type 
                                == AVMEDIA_TYPE_VIDEO)
    {
        videoStream = i;
        break;
    }
    if (videoStream == -1)
        return -1; // Didn't find a video stream

    // Get a pointer to the codec context for the video stream
    pCodecCtx = pFormatCtx->streams[videoStream]->codec;

    // Find the decoder for the video stream
    pCodec = avcodec_find_decoder(pCodecCtx->codec_id);
    if (pCodec == NULL) {
        fprintf(stderr, "Unsupported codec!\n");
        return -1; // Codec not found
    }
    // Open codec
    if (avcodec_open2(pCodecCtx, pCodec, NULL) < 0)
        return -1; // Could not open codec

    // Allocate video frame
    pFrame = avcodec_alloc_frame();

    int crop_x = 100, crop_y = 200, crop_h = 300, crop_w = 400;
    pFrameCropped = avcodec_alloc_frame();

    if (pFrameCropped == NULL)
        return -1;

    // Allocate an AVFrame structure
    pFrameRGB = avcodec_alloc_frame();
    if (pFrameRGB == NULL)
        return -1;

    // Determine required buffer size and allocate buffer
    numBytes = avpicture_get_size(PIX_FMT_RGB24, crop_w, crop_h);
    buffer = (uint8_t *) av_malloc(numBytes * sizeof(uint8_t));

    // Assign appropriate parts of buffer to image planes in pFrameRGB
    // Note that pFrameRGB is an AVFrame, but AVFrame is a superset
    // of AVPicture
    avpicture_fill((AVPicture *) pFrameRGB, buffer, PIX_FMT_RGB24, 
                   crop_w, crop_h);

    pSwsCtx = sws_getContext(crop_w, crop_h, pCodecCtx->pix_fmt, 
                             crop_w, crop_h, PIX_FMT_RGB24, 
                             SWS_FAST_BILINEAR, NULL, NULL, NULL);

    if (pSwsCtx == NULL) {
        fprintf(stderr, "Cannot initialize the sws context\n");
        return -1;
    }

    // Read frames and save first five frames to disk
    i = 0;
    while (av_read_frame(pFormatCtx, &packet) >= 0)
    {
        // Is this a packet from the video stream?
        if (packet.stream_index == videoStream)
        {   // Decode video frame
            avcodec_decode_video2(pCodecCtx, pFrame, 
                                  &frameFinished, &packet);

            // Did we get a video frame?
            if (frameFinished)
            {
                if (av_picture_crop((AVPicture *) pFrameCropped,
                                  (AVPicture *) pFrame, 
                                  PIX_FMT_YUV420P, crop_y, crop_x)< 0)
                {
                    fprintf(stderr, "error cropping picture\n");
                    return -1;
                }

                // Convert the image from its native format to RGB
                sws_scale(pSwsCtx,
                (const uint8_t * const *) pFrameCropped->data,
                pFrameCropped->linesize, 0, crop_h,
                pFrameRGB->data, pFrameRGB->linesize);

               // Save the frame to disk
               if (++i <= 5)
                   SaveFrame(pFrameRGB, crop_w, crop_h , i);
               else
                   break;
            }
        }

    // Free the packet that was allocated by av_read_frame
    av_free_packet(&packet);
    }

    // Free the RGB image
    av_free(buffer);
    av_free(pFrameRGB);

    // Free the YUV frame
    av_free(pFrame);

    // Close the codec
    avcodec_close(pCodecCtx);

    // Close the video file
    avformat_close_input(&pFormatCtx);

    return 0;
}
